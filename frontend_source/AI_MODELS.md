# AI Models (Updated: February 2026)

This document lists the available AI models integrated into the iCaffe platform as of **February 2026**.

## Google Gemini (3.0 Series)

| Model Name | ID | Description | Pricing (Input / Output) |
| :--- | :--- | :--- | :--- |
| **Gemini 3 Pro Preview** | `gemini-3-pro-preview` | The best model in the world for multimodal understanding and agentic tasks. | $2.00 / $12.00 (per 1M tokens) |
| **Gemini 3 Flash Preview** | `gemini-3-flash-preview` | Most intelligent model built for speed and efficiency. The standard default. | $0.50 / $3.00 (per 1M tokens) |
| **Gemini 3 Pro Image** | `gemini-3-pro-image-preview` | Native image generation model optimized for speed and flexibility. | $2.00 / $12.00 (Text), $0.134/image |

## Anthropic Claude (4.X Series)

| Model Name | ID | Description | Pricing (Input / Output) |
| :--- | :--- | :--- | :--- |
| **Claude Opus 4.6** | `claude-4-6-opus-latest` | Most intelligent model for building agents and complex coding tasks. | $5.00 / $25.00 (per 1M tokens) |
| **Claude Sonnet 4.6** | `claude-4-6-sonnet-latest` | Optimal balance of intelligence, cost, and speed. | $3.00 / $15.00 (per 1M tokens) |
| **Claude Haiku 4.5** | `claude-4-5-haiku-latest` | Fastest, most cost-efficient model. | $1.00 / $5.00 (per 1M tokens) |

## xAI Grok (4.0 Series)

| Model Name | ID | Description | Pricing (Input / Output) |
| :--- | :--- | :--- | :--- |
| **Grok 4.1 Fast Reasoning** | `grok-4-1-fast-reasoning` | Next generation tool-calling agent with reasoning capabilities. | $0.20 / $0.50 (per 1M tokens) |
| **Grok 4.1 Fast** | `grok-4-1-fast-non-reasoning` | Fast tool-calling agent without dedicated reasoning steps. | $0.20 / $0.50 (per 1M tokens) |
| **Grok Code Fast 1** | `grok-code-fast-1` | Lightning fast reasoning model built specifically for agentic coding. | $0.20 / $1.50 (per 1M tokens) |

## Local Models (Ollama)

| Model Name | ID | Description |
| :--- | :--- | :--- |
| **DictaLM 3.0 (1.7B)** | `dictalm-hebrew` | Specialized Hebrew model running locally. 1.7B params (1.1GB size). |
| **Llama 3.2 (3B)** | `llama3.2` | Small, fast reasoning model. |
| **DeepSeek R1 (7B)** | `deepseek-r1:7b` | Powerful reasoning model, optimized for complex tasks. |
| **Maya Custom** | `maya` | Custom fine-tuned local model. |
